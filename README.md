# ğŸ¤ Parkinson's Detection from Voice using speech patterns

ğŸ§ Audio Analysis for Parkinsonâ€™s Disease and Healthy Individuals

ğŸ§  For Parkinsonâ€™s Disease:


<img src="https://github.com/user-attachments/assets/8f7443db-69ac-4627-beb2-38092274be09" alt="Parkinson Audio 1" width="400"/> <img src="https://github.com/user-attachments/assets/4ae81780-c4f7-4384-9ed4-c0ebd29801d8" alt="Parkinson Audio 2" width="400"/>


ğŸ’ª For Healthy Audio:

<img src="https://github.com/user-attachments/assets/e09e9b74-0107-40f4-adf8-2b42ac97504b" alt="Healthy Audio 1" width="400"/> <img src="https://github.com/user-attachments/assets/1cdf66f9-9fa3-4248-99ac-c8f0b15cfdee" alt="Healthy Audio 2" width="400"/>


This project uses **CNN + XGBoost** to detect Parkinson's disease from voice recordings. The system extracts various audio features and predicts whether the individual is likely to have Parkinson's disease.

## ğŸ“š Dataset Used
The model was trained using the **Parkinson's Dataset** which contains voice measurements from healthy and Parkinsonâ€™s patients. The data includes features extracted from sustained phonation of the vowel `/a/`.

- **Dataset Path:** `parkinsons.data`
- **Target Variable:** `status` (0 = Healthy, 1 = Parkinsonâ€™s)
- **Feature Count:** 22 audio features

---

## ğŸš€ Key Features
- ğŸ’„ **Upload Audio File** â€“ Upload a `.wav` audio file.
- ğŸ§ **Real-time Prediction** â€“ Analyze the uploaded file and predict Parkinsonâ€™s status.
- ğŸ“ˆ **Audio Analysis Visualization** â€“ Display waveform and spectrogram for audio analysis.
- ğŸ¯ **Model Accuracy** â€“ Achieved 94% accuracy.

---

## ğŸ› ï¸ Models and Methods Used
### 1. **Convolutional Neural Network (CNN)**
- Extracts deep audio features.
- Architecture:
  - 3 convolutional layers with ReLU activation.
  - Max-pooling applied after each convolution.
  - Dense feature extraction layer (`feature_layer`).
  - Final dense layer with sigmoid activation for binary classification.

### 2. **XGBoost Classifier**
- Trained on deep features extracted from the CNN.
- Used for the final classification.

### ğŸ§© **Feature Extraction Methods:**
- **Pitch Features:** YIN algorithm for pitch extraction.
- **MFCC (Mel-frequency cepstral coefficients):** Extracts 13 MFCCs to capture audio characteristics.
- **Short-term Energy Entropy:** Derived from pyAudioAnalysis.
- **Harmonic-to-Noise Ratio (HNR):** Measures the ratio of harmonic to percussive components.
- **Tempo Feature:** Estimated using beat tracking.

---

## ğŸ¯ Model Performance
- âœ… **CNN + XGBoost Accuracy:** 94%
- ğŸ” **Evaluation Metrics:**
  - Precision, Recall, and F1-score evaluated using classification reports.

---

## ğŸ’‚ï¸ Project Structure
```
/parkinsons-voice-detection
â”œâ”€â”€ /models
â”‚   â”œâ”€â”€ scaler.pkl              # Scaler for feature normalization
â”‚   â”œâ”€â”€ feature_extractor.pkl   # CNN model for deep feature extraction
â”‚   â””â”€â”€ xgb_model.pkl           # XGBoost classifier model
â”œâ”€â”€ /data
â”‚   â””â”€â”€ parkinsons.data         # Dataset used for training
â”œâ”€â”€ app.py                      # Streamlit app for prediction
â””â”€â”€ README.md                   # Project documentation
```

---






## â–¶ï¸ Run the Application
```bash
streamlit run app.py
```


## ğŸ“Š Model Training
### CNN Model Training:
- Data normalized using `StandardScaler`.
- CNN architecture built with TensorFlow and Keras.
- Deep features extracted from the intermediate dense layer (`feature_layer`).
- Trained with 30 epochs and batch size of 8.

### XGBoost Training:
- XGBoost classifier trained on extracted deep features.
- Evaluation performed using classification metrics and cross-validation.

---

## ğŸ“ Usage Instructions
1. Launch the Streamlit application.
2. Upload an audio file in `.wav` format.
3. The model extracts audio features and displays:
    - Prediction result with confidence score.
    - Audio waveform and spectrogram analysis.


---


